{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoogTech/langchain-tutorials/blob/master/Agents/Build_an_Agent.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Refer to : https://python.langchain.com/docs/tutorials/agents/"
      ],
      "metadata": {
        "id": "37LROHv5knGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "KyotJAMDG4jA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By themselves, language models can't take actions - they just output text. A big use case for LangChain is creating agents. **Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action.**"
      ],
      "metadata": {
        "id": "TmBty7qkHDlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it."
      ],
      "metadata": {
        "id": "IwUh7rp2HUx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "Fh5TLtsDIE7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langgraph langchain-community langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B94g22SeIPMU",
        "outputId": "086fca1f-5062-4242-ee14-70b0c75f30d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.71)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.12)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.51)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34b8VekFIngH",
        "outputId": "55ee554a-8b7a-4e39-dde7-7dc40da527ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.1-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81.9/91.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.8.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Downloading tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain langgraph langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXS2VO9GkGr1",
        "outputId": "436a636b-f1dd-4552-ba21-39638dafd221"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.18\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: langchain-community\n",
            "---\n",
            "Name: langgraph\n",
            "Version: 0.2.71\n",
            "Summary: Building stateful, multi-actor applications with LLMs\n",
            "Home-page: https://www.github.com/langchain-ai/langgraph\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: langchain-core, langgraph-checkpoint, langgraph-sdk\n",
            "Required-by: \n",
            "---\n",
            "Name: langchain-openai\n",
            "Version: 0.3.5\n",
            "Summary: An integration package connecting OpenAI and LangChain\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: langchain-core, openai, tiktoken\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define tools"
      ],
      "metadata": {
        "id": "S-GDaBN_JCED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool."
      ],
      "metadata": {
        "id": "hf2e5xYeJNSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "1nPbJOOMP591"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=2)\n",
        "search_results = search.invoke(\"what is the weather in SF\")\n",
        "print(search_results)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JghLlkE4JQRj",
        "outputId": "a6bb79f1-8395-4f3a-b274-864f37b03a51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1739362843, 'localtime': '2025-02-12 04:20'}, 'current': {'last_updated_epoch': 1739362500, 'last_updated': '2025-02-12 04:15', 'temp_c': 6.7, 'temp_f': 44.1, 'is_day': 0, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 8.9, 'wind_kph': 14.4, 'wind_degree': 77, 'wind_dir': 'ENE', 'pressure_mb': 1013.0, 'pressure_in': 29.92, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 89, 'cloud': 100, 'feelslike_c': 3.9, 'feelslike_f': 39.1, 'windchill_c': 4.1, 'windchill_f': 39.4, 'heatindex_c': 6.3, 'heatindex_f': 43.4, 'dewpoint_c': 4.9, 'dewpoint_f': 40.8, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 12.4, 'gust_kph': 19.9}}\"}, {'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-12', 'content': \"Wednesday, February 12, 2025. San Francisco, CA - Weather Forecast San Francisco, CA Home Contact Browse States Privacy Policy Terms and Conditions Today Tomorrow Hourly 7 days 30 days February San Francisco, California Weather: Flood Watch (Flooding is possible in the near future; stay informed and prepared for potential evacuation or disruptions) High Wind Watch (Potential for dangerously strong winds that could cause damage, power outages, and hazardous travel. Stay alert for changing conditions.) Wednesday, February 12, 2025 Day 55° Night 50° Wind 12 mph 7 days 30 days Weather Forecast History Last Year's Weather on This Day (February 12, 2024) Day 61° Night 46° Please note that while we strive for accuracy, the information provided may not always be correct.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Language Models"
      ],
      "metadata": {
        "id": "OyHVVyedQss7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably."
      ],
      "metadata": {
        "id": "h6DRz4HnQ45P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Call the model\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "\n",
        "# Print the response from model\n",
        "print(response, '\\n')\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqYWltcBQ8sq",
        "outputId": "922e5867-04b3-4f2a-e314-ecc00989544a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None} id='run-15834023-4871-461a-9d47-e6922a861e52-0' usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} \n",
            "\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now see what it is like to enable this model to do tool calling. In order to enable that we use `.bind_tools` to give the language model knowledge of these tools"
      ],
      "metadata": {
        "id": "xe_tUBbNRu1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Call the model\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "# Print the response from model\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23eutdaJQ8lu",
        "outputId": "eefbe3cd-d352-422f-e679-37dda2bc6301"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: Hello! How can I assist you today?\n",
            "ToolCalls: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try calling it with some input that would expect a tool to be called."
      ],
      "metadata": {
        "id": "VhNN104ATLEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Call the model\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
        "\n",
        "# Print the response from model\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYAADRGKTLtk",
        "outputId": "1a12d7ae-5b10-4f78-b973-09df12d80e24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: \n",
            "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco current weather'}, 'id': 'call_qNdbkuX8y1stCkc0sfuwF5qe', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
        "\n",
        "**This isn't calling that tool yet - it's just telling us to.** In order to actually call it, we'll want to create our agent."
      ],
      "metadata": {
        "id": "Efn5wxdtTk8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the agent"
      ],
      "metadata": {
        "id": "q9HMa9gSTqrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent."
      ],
      "metadata": {
        "id": "bHwuqxt2XKsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Initialize the agent with the LLM and the tools\n",
        "agent_executor = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "N1uuEIGMXORp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the agent"
      ],
      "metadata": {
        "id": "umkOzBQOX-NH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First up, let's see how it responds when there's no need to call a tool:"
      ],
      "metadata": {
        "id": "ClI7gq5rY8AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Initialize the agent with the LLM and the tools\n",
        "agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "# Run the agent\n",
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4frjsHL-X_nn",
        "outputId": "fa4b0ec9-8061-434f-b8c5-8a9b1703b14c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='7913c79a-0753-4f6e-9c15-000c6f0ce0d8'),\n",
              " AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 81, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-48a470af-cbf0-44a9-9357-6df71c47b461-0', usage_metadata={'input_tokens': 81, 'output_tokens': 10, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now try it out on an example where it should be invoking the tool:"
      ],
      "metadata": {
        "id": "eu0FMQMbY-g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Initialize the agent with the LLM and the tools\n",
        "agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "# Run the agent\n",
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]})\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdjDH8cfYu-g",
        "outputId": "e45aa047-192d-4574-9407-a982573ad88e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}, id='e6e2f06b-8572-493c-8783-008fc743760a'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FAJJiTFIWnxb2ATfghA03e6H', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 86, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cd2df1f5-c724-4201-8399-983ba60132d3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_FAJJiTFIWnxb2ATfghA03e6H', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 22, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739367793, \\'localtime\\': \\'2025-02-12 05:43\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739367000, \\'last_updated\\': \\'2025-02-12 05:30\\', \\'temp_c\\': 7.2, \\'temp_f\\': 45.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 9.4, \\'wind_kph\\': 15.1, \\'wind_degree\\': 65, \\'wind_dir\\': \\'ENE\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 75, \\'feelslike_c\\': 4.4, \\'feelslike_f\\': 40.0, \\'windchill_c\\': 4.4, \\'windchill_f\\': 39.8, \\'heatindex_c\\': 6.8, \\'heatindex_f\\': 44.2, \\'dewpoint_c\\': 5.0, \\'dewpoint_f\\': 41.0, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.0, \\'gust_kph\\': 21.0}}\"}, {\"url\": \"https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-12\", \"content\": \"Wednesday, February 12, 2025. San Francisco, CA - Weather Forecast San Francisco, CA Home Contact Browse States Privacy Policy Terms and Conditions Today Tomorrow Hourly 7 days 30 days February San Francisco, California Weather: Flood Watch (Flooding is possible in the near future; stay informed and prepared for potential evacuation or disruptions) High Wind Watch (Potential for dangerously strong winds that could cause damage, power outages, and hazardous travel. Stay alert for changing conditions.) Wednesday, February 12, 2025 Day 55° Night 50° Wind 12 mph 7 days 30 days Weather Forecast History Last Year\\'s Weather on This Day (February 12, 2024) Day 61° Night 46° Please note that while we strive for accuracy, the information provided may not always be correct.\"}]', name='tavily_search_results_json', id='c93cc14d-e0f6-47b0-aacb-7889f5897a1d', tool_call_id='call_FAJJiTFIWnxb2ATfghA03e6H', artifact={'query': 'current weather in San Francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1739367793, 'localtime': '2025-02-12 05:43'}, 'current': {'last_updated_epoch': 1739367000, 'last_updated': '2025-02-12 05:30', 'temp_c': 7.2, 'temp_f': 45.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 65, 'wind_dir': 'ENE', 'pressure_mb': 1013.0, 'pressure_in': 29.91, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 86, 'cloud': 75, 'feelslike_c': 4.4, 'feelslike_f': 40.0, 'windchill_c': 4.4, 'windchill_f': 39.8, 'heatindex_c': 6.8, 'heatindex_f': 44.2, 'dewpoint_c': 5.0, 'dewpoint_f': 41.0, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 13.0, 'gust_kph': 21.0}}\", 'score': 0.9728016, 'raw_content': None}, {'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-12', 'title': 'Wednesday, February 12, 2025. San Francisco, CA - WeatherShogun', 'content': \"Wednesday, February 12, 2025. San Francisco, CA - Weather Forecast San Francisco, CA Home Contact Browse States Privacy Policy Terms and Conditions Today Tomorrow Hourly 7 days 30 days February San Francisco, California Weather: Flood Watch (Flooding is possible in the near future; stay informed and prepared for potential evacuation or disruptions) High Wind Watch (Potential for dangerously strong winds that could cause damage, power outages, and hazardous travel. Stay alert for changing conditions.) Wednesday, February 12, 2025 Day 55° Night 50° Wind 12 mph 7 days 30 days Weather Forecast History Last Year's Weather on This Day (February 12, 2024) Day 61° Night 46° Please note that while we strive for accuracy, the information provided may not always be correct.\", 'score': 0.92715925, 'raw_content': None}], 'response_time': 1.71}),\n",
              " AIMessage(content='The current weather in San Francisco is as follows:\\n\\n- **Temperature:** 7.2°C (45°F)\\n- **Condition:** Partly cloudy\\n- **Wind:** 9.4 mph (15.1 kph) coming from the ENE\\n- **Humidity:** 86%\\n- **Visibility:** 16 km (9 miles)\\n\\nAdditionally, there are some weather alerts in effect:\\n- **Flood Watch:** Flooding is possible in the near future; stay informed for potential evacuations or disruptions.\\n- **High Wind Watch:** There is a potential for dangerously strong winds that could cause damage and power outages.\\n\\nFor more detailed forecasts, you can check sources like [WeatherAPI](https://www.weatherapi.com/) or [Weather Shogun](https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-12).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 185, 'prompt_tokens': 731, 'total_tokens': 916, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dc32dff6-1589-4ac1-9c0c-ebb9636f0d6d-0', usage_metadata={'input_tokens': 731, 'output_tokens': 185, 'total_tokens': 916, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming Messages"
      ],
      "metadata": {
        "id": "CSHQAuu-ZSaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've seen how the agent can be called with `.invoke` to get a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back messages as they occur."
      ],
      "metadata": {
        "id": "PEqT_ychamDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Initialize the agent with the LLM and the tools\n",
        "agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "# Run the agent\n",
        "for chunk in agent_executor.stream({\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}):\n",
        "    print(chunk)\n",
        "    print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKwZTyGya-E4",
        "outputId": "f7f02e03-1910-45ce-c713-237faae81e3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_orgSD0AQpT7RCreOkoJRtnzs', 'function': {'arguments': '{\"query\":\"San Francisco weather today\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-71f5d8ce-c6b0-452c-a5b5-54e94f9c1351-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_orgSD0AQpT7RCreOkoJRtnzs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "---\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739368187, \\'localtime\\': \\'2025-02-12 05:49\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739367900, \\'last_updated\\': \\'2025-02-12 05:45\\', \\'temp_c\\': 7.2, \\'temp_f\\': 45.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 9.4, \\'wind_kph\\': 15.1, \\'wind_degree\\': 65, \\'wind_dir\\': \\'ENE\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 75, \\'feelslike_c\\': 4.4, \\'feelslike_f\\': 40.0, \\'windchill_c\\': 4.4, \\'windchill_f\\': 39.8, \\'heatindex_c\\': 6.8, \\'heatindex_f\\': 44.2, \\'dewpoint_c\\': 5.0, \\'dewpoint_f\\': 41.0, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.0, \\'gust_kph\\': 21.0}}\"}, {\"url\": \"https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-12\", \"content\": \"Wednesday, February 12, 2025. San Francisco, CA - Weather Forecast San Francisco, CA Home Contact Browse States Privacy Policy Terms and Conditions Today Tomorrow Hourly 7 days 30 days February San Francisco, California Weather: Flood Watch (Flooding is possible in the near future; stay informed and prepared for potential evacuation or disruptions) High Wind Watch (Potential for dangerously strong winds that could cause damage, power outages, and hazardous travel. Stay alert for changing conditions.) Wednesday, February 12, 2025 Day 55° Night 50° Wind 12 mph 7 days 30 days Weather Forecast History Last Year\\'s Weather on This Day (February 12, 2024) Day 61° Night 46° Please note that while we strive for accuracy, the information provided may not always be correct.\"}]', name='tavily_search_results_json', id='0593df0f-d70a-47c2-8973-44b050719da1', tool_call_id='call_orgSD0AQpT7RCreOkoJRtnzs', artifact={'query': 'San Francisco weather today', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1739368187, 'localtime': '2025-02-12 05:49'}, 'current': {'last_updated_epoch': 1739367900, 'last_updated': '2025-02-12 05:45', 'temp_c': 7.2, 'temp_f': 45.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 65, 'wind_dir': 'ENE', 'pressure_mb': 1013.0, 'pressure_in': 29.91, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 86, 'cloud': 75, 'feelslike_c': 4.4, 'feelslike_f': 40.0, 'windchill_c': 4.4, 'windchill_f': 39.8, 'heatindex_c': 6.8, 'heatindex_f': 44.2, 'dewpoint_c': 5.0, 'dewpoint_f': 41.0, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 13.0, 'gust_kph': 21.0}}\", 'score': 0.967866, 'raw_content': None}, {'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/february/2025-02-12', 'title': 'Wednesday, February 12, 2025. San Francisco, CA - WeatherShogun', 'content': \"Wednesday, February 12, 2025. San Francisco, CA - Weather Forecast San Francisco, CA Home Contact Browse States Privacy Policy Terms and Conditions Today Tomorrow Hourly 7 days 30 days February San Francisco, California Weather: Flood Watch (Flooding is possible in the near future; stay informed and prepared for potential evacuation or disruptions) High Wind Watch (Potential for dangerously strong winds that could cause damage, power outages, and hazardous travel. Stay alert for changing conditions.) Wednesday, February 12, 2025 Day 55° Night 50° Wind 12 mph 7 days 30 days Weather Forecast History Last Year's Weather on This Day (February 12, 2024) Day 61° Night 46° Please note that while we strive for accuracy, the information provided may not always be correct.\", 'score': 0.95100147, 'raw_content': None}], 'response_time': 1.68})]}}\n",
            "---\n",
            "{'agent': {'messages': [AIMessage(content=\"The current weather in San Francisco is partly cloudy with a temperature of 45°F (7.2°C). The humidity is high at 86%, and there is no precipitation reported. The wind is blowing from the east-northeast at 9.4 mph.\\n\\nAdditionally, there are some weather alerts in effect:\\n- **Flood Watch:** Flooding is possible in the near future, so it's advisable to stay informed and prepared for potential evacuations or disruptions.\\n- **High Wind Watch:** There is a potential for dangerously strong winds that could cause damage, power outages, and hazardous travel. \\n\\nOverall, expect highs around 55°F and lows at night around 50°F. \\n\\nFor more details, you can check the [weather forecast here](https://www.weatherapi.com/).\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 160, 'prompt_tokens': 730, 'total_tokens': 890, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3b7d4f06-9e63-45d1-84cd-bfa200099e73-0', usage_metadata={'input_tokens': 730, 'output_tokens': 160, 'total_tokens': 890, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming tokens❌\n",
        "... It's confusing for beginners ..."
      ],
      "metadata": {
        "id": "8ohuLyq5bNub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding in memory"
      ],
      "metadata": {
        "id": "b8yXY7TAcLG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from)."
      ],
      "metadata": {
        "id": "9o2J21EWcXnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Initialize the search tool\n",
        "search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]\n",
        "\n",
        "# Initialize a ChatModel from the model name and provider\n",
        "model = init_chat_model(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_provider=\"openai\",\n",
        "    openai_api_key=userdata.get('OPENAI_API_KEY'),\n",
        "    base_url=userdata.get('BASE_URL'),\n",
        ")\n",
        "\n",
        "# Initialize the in-memory checkpoint saver\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Initialize the agent with the LLM, tools and the memory\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
      ],
      "metadata": {
        "id": "541Dx7DjcKy3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This enables us to support multiple conversation threads with a single application,\n",
        "# a common requirement when your application has multiple users.\n",
        "config = {\"configurable\": {\"thread_id\": \"thread_id_000\"}}\n",
        "\n",
        "# Run the agent\n",
        "for chunk in agent_executor.stream(\n",
        "    input={\"messages\": [HumanMessage(content=\"Hi I'm Hack\")]},\n",
        "    config=config,\n",
        "):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StFiLAbkdt2Q",
        "outputId": "71ebac8d-9a95-456a-eb31-72b30ffdc644"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"Hello, Hack! It's nice to see you again. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 176, 'total_tokens': 195, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bfef2a7e-eb26-4f35-b4ad-be7be069d841-0', usage_metadata={'input_tokens': 176, 'output_tokens': 19, 'total_tokens': 195, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This enables us to support multiple conversation threads with a single application,\n",
        "# a common requirement when your application has multiple users.\n",
        "config = {\"configurable\": {\"thread_id\": \"thread_id_000\"}}\n",
        "\n",
        "# Run the agent\n",
        "for chunk in agent_executor.stream(\n",
        "    input={\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
        "    config=config,\n",
        "):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElVA_76Kd3lV",
        "outputId": "0213b6a4-7c92-4ea2-b12f-8d5e65d73c94"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Your name is Hack. How can I assist you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 206, 'total_tokens': 219, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1d3c8070-42a5-4c66-a756-8215c03ec716-0', usage_metadata={'input_tokens': 206, 'output_tokens': 13, 'total_tokens': 219, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to start a new conversation, all you have to do is change the thread_id used:"
      ],
      "metadata": {
        "id": "vr2YhEYjeFKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This enables us to support multiple conversation threads with a single application,\n",
        "# a common requirement when your application has multiple users.\n",
        "config = {\"configurable\": {\"thread_id\": \"thread_id_111\"}}\n",
        "\n",
        "# Run the agent\n",
        "for chunk in agent_executor.stream(\n",
        "    input={\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
        "    config=config,\n",
        "):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS8pWahgeLUv",
        "outputId": "0613a35d-a823-4b67-d81c-42c5b761d47c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='I still don’t have that information. If you let me know your name, I can remember it for the duration of our conversation!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 128, 'total_tokens': 156, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1772330c-0e8e-4f1f-8078-b22138f47234-0', usage_metadata={'input_tokens': 128, 'output_tokens': 28, 'total_tokens': 156, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
          ]
        }
      ]
    }
  ]
}